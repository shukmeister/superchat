Milestone 1: 1x1 Chat

1.1. ✅ Scaffold project structure and install dependencies (pyautogen)
1.2. ✅ Implement CLI entry-point (superchat / sc) with argparse stub
1.3. ✅ Build setup loop: display ASCII "SUPERCHAT" banner and session info panel
1.4. ✅ Write a function to separate commands (e.g., /model) from chat messages.
1.5. ✅ Store selected model(s) in an in-memory config 
1.6. ✅ Define per-agent background-prompt templates in code
1.7. ✅ Implement /start: initialize chat session for one model and enter chat loop. Chat UI has a >>>
1.7.1. ✅ Add /start command handler to setup loop with validation (exactly 1 model required)
1.7.2. ✅ Create AutoGen agent initialization for single model (no debate prompt for 1:1)
1.7.3. ✅ Implement basic chat input loop with >>> prompt
1.7.4. ✅ Configure model API connection through AutoGen
1.7.5. ✅ Add agent response rendering and formatting
1.7.6. ✅ Implement /exit command to end chat session
1.8. ✅ In chat loop, read user input, call model API, render response
1.9. ✅ Implement /exit to end the session

Milestone 2: 1x N Debate

2.1. ☐ Create setup commands: /list, /model <slot> <name>, /remove <name>
2.2. ☐ Extend config to hold multiple model slots; add several more models
2.3. ☐ Prevent multiple of the same model from being selected
2.4. ☐ After /start with >1 models, broadcast prompt to all agents in sequence (After /start, allow sequential private chats with each model.)
2.5. ☐ Create logic for 1:1 chat commands: /promote, /restart, /boot
2.6. ☐ Upon /promote, append that agent's transcript to a shared "debate context" buffer
2.7. ☐ After all slots processed, assemble debate:
   show original prompt once at top
   dump transcripts in slot order
   switch to round-robin multi-agent loop (in slot order)
2.8. ☐ In multi-agent loop: on each "turn" (user text or empty), loop through active agents, include full shared context + history, solicit reply
2.9. ☐ Honor /boot to remove agents mid-debate; support implicit empty-input turns
3.0 Create /ask command to ask a specific agent a follow up question

Milestone 3: CLI-Flag Shortcuts

3.1. ☐ Define CLI flags (--model/-m, --voice/-v, etc.) in argparse alongside subcommands
3.2. ☐ Map flags to the setup config (skip interactive setup when flags present)
3.3. ☐ Auto-invoke /start when minimal flags given (e.g. one model)
3.4. ☐ Ensure CLI parameters take priority over default settings
3.5. ☐ Validate flags (no duplicate models, unknown flags) and error out
3.6. ☐ Track and accumulate token counts, rounds, elapsed time; update on each turn; implement /stats
3.7. ☐ On /exit, print summary (tokens, costs) and terminate
3.8. ☐ /help command and update help text to include flag usage examples

(BELOW THE LINE/DO NOT IMPLEMENT):

Milestone 4: Voice

Milestone 5: Threaded Conversations

(?) P2: Threaded conversation system (replacing round robin) - Implement a system where each message has a unique ID and can reply to another via a reply_to field, forming threads. Models respond only to specific messages by ID or when invited by the user with commands like /open for general input, ensuring controlled and relevant model participation.

Other

- Add russian symbol to single chat
- Add more info to session, spruce it up
- Make it more readable
- Make default > and then during chat >>